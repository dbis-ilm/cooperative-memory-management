#include <gflags/gflags.h>

#include <algorithm>
#include <atomic>
#include <cassert>
#include <chrono>
#include <cmath>
#include <fstream>
#include <iostream>
#include <numeric>
#include <vector>
#include <sched.h>
#include <sstream>
#include <unordered_map>
#include <unordered_set>
#include <set>

#include "prototype/execution/join.hpp"
#include "prototype/execution/qep.hpp"
#include "prototype/execution/sort.hpp"
#include "prototype/execution/temporary_column.hpp"
#include "prototype/scheduling/job_manager.hpp"
#include "prototype/storage/persistence/btree.hpp"
#include "prototype/storage/persistence/table.hpp"
#include "prototype/storage/policy/basic_partitioning_strategy.hpp"
#include "prototype/storage/policy/cache_partition.hpp"
#include "prototype/storage/policy/data_temp_partitioning_strategy.hpp"
#include "prototype/storage/vmcache.hpp"
#include "prototype/utils/errno.hpp"
#include "prototype/utils/print_result.hpp"
#include "execution/q06_scan.hpp"
#include "execution/q06_agg.hpp"
#include "execution/q09_agg.hpp"
#include "execution/q09_item_scan.hpp"
#include "execution/q09_order_scan.hpp"
#include "execution/q09_stock_scan.hpp"
#include "tpcch.hpp"
#include "transactions.hpp"

#ifdef VTUNE_PROFILING
#include <ittnotify.h>

__itt_domain* itt_domain = __itt_domain_create("tpcch");
__itt_string_handle* itt_handle_setup = __itt_string_handle_create("setup");
__itt_string_handle* itt_handle_load = __itt_string_handle_create("load");
#endif

DEFINE_string(ch_path, "", "Path to the CH csv ([tablename].tbl) files generated by dbgen");
DEFINE_uint64(parallel, 0, "Number of threads to use; defaults to using all available threads");
DEFINE_uint64(oltp, 64, "Number of concurrent OLTP streams to run");
DEFINE_string(olap, "simulated", "The type of OLAP workload to run; options are 'simulated', 'q06', 'q09', 'mixed', and 'none'; 'mixed' alternates between running q06 and q09; defaults to 'simulated'");
DEFINE_uint64(olap_interval, 30, "Interval in seconds to run analytical queries at (i.e., an analytical query is started every 'olap_interval' seconds); a new query is only started after the previous one has finished, so specifying an interval that is smaller than the query's actual execution time (or 0) will result in queries being executed back-to-back and can be used to measure maximum analytical throughput; the default value is 30 seconds");
DEFINE_uint64(olap_sim_duration, 5, "Duration in seconds for the simulated OLAP query; defaults to 5 seconds");
DEFINE_bool(olap_stdout, false, "Print OLAP query results to the standard output");
DEFINE_uint64(warmup, 10, "Warmup time in seconds");
DEFINE_uint64(benchmark, 60, "Benchmark time in seconds");
DEFINE_int64(oltp_pause, -1, "Time in seconds (including warmup) after which OLTP streams are paused for 10 seconds; negative values imply no pause, defaults to -1");
DEFINE_bool(sandbox, false, "Run in sandbox mode (any changes to the database will not be persisted)");
DEFINE_bool(no_dirty_writeback, false, "Disable writing back dirty pages to disk; Warning: This will result in data loss!");
DEFINE_bool(no_async_flush, false, "Disable asynchronous flushing of dirty pages using idle worker threads");
DEFINE_bool(no_eviction_target, false, "Disable eviction target mechanism for avoiding interference between large temporary allocations and regular buffer pool traffic");
DEFINE_bool(exmap, false, "Use exmap (kernel module has to be loaded) to reduce vmcache overhead");
DEFINE_bool(import_only, false, "Only import input data, do not run query");
DEFINE_bool(full_validation, false, "Perform full validation; without this flag, the cardinality of large indices is not validated");
DEFINE_string(collect_stats, "", "Collect statistics while running the queries into the specified path in CSV format");
DEFINE_string(latency_log, "", "Collect measured latencies for queries/transactions into the specified path in CSV format");
DEFINE_bool(collect_latched_page_stat, false, "Include the number of latched data pages in the collected statistics; this has high overhead as it involves iterating over all cached pages at each collection interval");
DEFINE_string(partitioning_strategy, "basic", "Partitioning strategy to use in vmcache; options are 'basic' and 'partitioned' (uses separate partitions for data and temporary pages)");
DEFINE_string(eviction_policy, "clock", "Eviction policy to use within vmcache partitions; options are 'clock', 'random', and 'mru'");
DEFINE_uint64(partitioned_num_temp_pages, 0, "Number of pages to allocate to temporary data if the cache is partitioned");
DEFINE_uint64(memory_limit, 16ull * 1024ull * 1024ull * 1024ull, "Memory limit");

namespace tpcch {

const auto S_SUPPKEY = NamedColumn(std::string("S_SUPPKEY"), std::make_shared<UnencodedTemporaryColumn<Identifier>>());
const auto L_YEAR = NamedColumn(std::string("L_YEAR"), std::make_shared<UnencodedTemporaryColumn<Integer>>());
const auto SUM_PROFIT = NamedColumn(std::string("SUM_PROFIT"), std::make_shared<UnencodedTemporaryColumn<Decimal<2>>>());

bool loadDatabase(DB& db, const ExecutionContext context) {
    std::cout << "Loading data..." << std::endl;
    createTables(db, context);
    importFromCSV(db, FLAGS_ch_path, context);
    db.vmcache.printMemoryUsage();
    std::cout << "Creating primary key indexes..." << std::endl;
    createIndexes(db, context);
    db.vmcache.printMemoryUsage();
    return true;
}

void statsCollectorThread(const std::string& path, bool& stop, const DB& db, std::atomic_size_t& no_success_count, size_t collection_interval_ms) {
    std::ofstream file(path);
    if (!file) {
        std::cerr << "Could not open '" << path << "' for writing stats, aborting stats collection" << std::endl;
        stop = true;
        return;
    }
    // see https://www.kernel.org/doc/html/latest/filesystems/proc.html, Table 1-3
    int statm_fd = open("/proc/self/statm", O_RDONLY | O_CLOEXEC);
    if (statm_fd == -1) {
        std::cerr << "Could not open '/proc/self/statm' for getting memory stats, aborting stats collection" << std::endl;
        stop = true;
        return;
    }
    file << "elapsed,data_pages,dirty_data_pages,temp_pages,accessed_pages,faulted_pages,evicted_pages,dirty_write_pages";
    if (FLAGS_collect_latched_page_stat)
        file << ",data_latched";
    file << ",temp_in_use";
    file << ",no_success_count";
    file << ",statm_size,statm_resident,statm_shared";
    file << std::endl;
    size_t prev_faulted_pages = 0;
    size_t prev_accessed_pages = 0;
    size_t prev_evicted_pages = 0;
    size_t prev_dirty_write_pages = 0;
    auto begin = std::chrono::steady_clock::now();
    const size_t page_size = sysconf(_SC_PAGESIZE);
    while (!stop) {
        std::this_thread::sleep_for(std::chrono::milliseconds(collection_interval_ms));
        double elapsed_seconds = std::chrono::duration_cast<std::chrono::duration<double>>(std::chrono::steady_clock::now() - begin).count();
        file << elapsed_seconds;
        // internal stats
        file << "," << db.vmcache.getPartitions().getCurrentPhysicalDataPageCount();
        file << "," << db.vmcache.getDirtyPageCount();
        file << "," << db.vmcache.getMaxPhysicalPages() - db.vmcache.getPartitions().getCurrentPhysicalDataPageCount();
        const size_t accessed_pages = db.vmcache.getTotalAccessedPageCount();
        file << "," << accessed_pages - prev_accessed_pages;
        prev_accessed_pages = accessed_pages;
        const size_t faulted_pages = db.vmcache.getTotalFaultedPageCount();
        file << "," << faulted_pages - prev_faulted_pages;
        prev_faulted_pages = faulted_pages;
        const size_t evicted_pages = db.vmcache.getTotalEvictedPageCount();
        file << "," << evicted_pages - prev_evicted_pages;
        prev_evicted_pages = evicted_pages;
        const size_t dirty_write_pages = db.vmcache.getTotalDirtyWritePageCount();
        file << "," << dirty_write_pages - prev_dirty_write_pages;
        prev_dirty_write_pages = dirty_write_pages;
        if (FLAGS_collect_latched_page_stat)
            file << "," << db.vmcache.getNumLatchedDataPages();
        file << "," << db.vmcache.getNumTemporaryPagesInUse();
        file << "," << no_success_count.exchange(0);
        // OS memory stats
        constexpr size_t statm_buf_size = 1024;
        char statm_buf[statm_buf_size];
        int statm_res = pread(statm_fd, statm_buf, statm_buf_size, 0);
        size_t statm_size;
        size_t statm_resident;
        size_t statm_shared;
        if (statm_res != -1 && sscanf(statm_buf, "%lu %lu %lu", &statm_size, &statm_resident, &statm_shared) == 3) {
            file << "," << statm_size * page_size << "," << statm_resident * page_size << "," << statm_shared * page_size;
        } else {
            file << ",,,"; // output nan
        }
        // prepare for next interval
        file << std::endl;
    }
    close(statm_fd);
}

class DataSource {
public:
    DataSource(uint32_t num_warehouses, unsigned seed = 0) : num_warehouses(num_warehouses), generator(seed) { }

    int32_t randomUniformInt(int32_t min, int32_t max) {
        std::uniform_int_distribution<int32_t> dist(min, max);
        return dist(generator);
    }

    int32_t randomNonUniformInt(int32_t A, int32_t x, int32_t y, int32_t C) {
        // generate c_id using NURand(1023, 1, 3000), see TPC-C spec, p. 21
        std::uniform_int_distribution<uint32_t> exp1dist(0, A);
        std::uniform_int_distribution<uint32_t> exp2dist(x, y);
        return (((exp1dist(generator) | exp2dist(generator)) + C) % (y - x + 1)) + x;
    }

    int32_t getRemoteWId(int32_t local_w_id) {
        int32_t ret;
        if (num_warehouses == 1) {
            ret = local_w_id;
        } else {
            ret = local_w_id;
            while (ret == local_w_id)
                ret = randomUniformInt(1, num_warehouses);
        }
        return ret;
    }

    uint64_t getCurrentTimestamp() {
        time_t rawtime;
        time(&rawtime);
        tm* timeinfo = localtime(&rawtime);
        return encode_date_time(timeinfo->tm_year + 1900, timeinfo->tm_mon + 1, timeinfo->tm_mday, timeinfo->tm_hour, timeinfo->tm_min, timeinfo->tm_sec);
    }

    std::string genCLast(int32_t value){
        std::string ret;
        ret += c_last_parts[value / 100];
        value %= 100;
        ret += c_last_parts[value / 10];
        value %= 10;
        ret += c_last_parts[value];
        return ret;
    }

    std::string randomCLast() {
        return genCLast(randomNonUniformInt(255, 0, 999, 173));
    }

private:
    const uint32_t num_warehouses;
    std::mt19937 generator;
    std::vector<const char*> c_last_parts = {
        "BAR", "OUGHT", "ABLE", "PRI", "PRES", "ESE", "ANTI", "CALLY", "ATION", "EING"
    };
};

bool executeNewOrder(std::ostream& log, DataSource& ds, DB& db, Identifier w_id, const ExecutionContext context) {
    // 2.4.1.2
    Identifier d_id = ds.randomUniformInt(1, 10);
    Identifier c_id = ds.randomNonUniformInt(1023, 1, 3000, 867);
    // 2.4.1.3
    uint32_t ol_cnt = ds.randomUniformInt(5, 15);
    // 2.4.1.4
    bool random_rollback = ds.randomUniformInt(1, 100) == 1;
    // 2.4.1.5
	bool all_local = true;
	OrderLine orderlines[15];
	for (size_t i = 0; i < ol_cnt; i++) {
		// 1.
		if (i == ol_cnt - 1 && random_rollback) {
			orderlines[i].ol_i_id = 100001;
        } else {
			orderlines[i].ol_i_id = ds.randomNonUniformInt(8191, 1, 100000, 5867);
        }
		// 2.
		if (ds.randomUniformInt(1, 100) == 1) {
			orderlines[i].ol_supply_w_id = ds.getRemoteWId(w_id);
			orderlines[i].ol_is_remote = true;
			all_local = false;
		} else {
			orderlines[i].ol_supply_w_id = w_id;
			orderlines[i].ol_is_remote = false;
		}
		// 3.
		orderlines[i].ol_quantity = ds.randomUniformInt(1, 10);
	}
	// 2.4.1.6
	DateTime o_entry_d(ds.getCurrentTimestamp());

    return runNewOrder(log, db, w_id, d_id, c_id, orderlines, ol_cnt, all_local, o_entry_d, context);
}

bool executePayment(std::ostream& log, DataSource& ds, DB& db, Identifier w_id, const ExecutionContext context) {
    // 2.5.1.2
	Identifier d_id = ds.randomUniformInt(1, 10);

	Identifier c_d_id = 0;
	Identifier c_w_id = 0;
	if (ds.randomUniformInt(1, 100) <= 85) {
		c_d_id = d_id;
		c_w_id = w_id;
	} else {
		c_d_id = ds.randomUniformInt(1, 10);
		c_w_id = ds.getRemoteWId(w_id);
	}

	Identifier c_id = 0;
	std::string c_last;
	bool customer_based_on_last_name = ds.randomUniformInt(1, 100) <= 60;
	if (customer_based_on_last_name) {
		c_last = ds.randomCLast();
	} else {
		c_id = ds.randomNonUniformInt(1023, 1, 3000, 867);
	}

	// 2.5.1.3
	Decimal<2> h_amount(ds.randomUniformInt(100, 500000)); // random decimal between 1.00 and 5000.00

	// 2.5.1.4
    DateTime h_date(ds.getCurrentTimestamp());

    return runPayment(log, db, w_id, d_id, c_w_id, c_d_id, customer_based_on_last_name, c_id, c_last, h_amount, h_date, context);
}

bool executeOrderStatus(std::ostream& log, DataSource& ds, DB& db, Identifier w_id, const ExecutionContext context) {
	// 2.6.1.2
	int32_t d_id = ds.randomUniformInt(1, 10);
	bool customer_based_on_last_name = ds.randomUniformInt(1, 100) <= 60;
	int32_t c_id = 0;
	std::string c_last;
	if (customer_based_on_last_name) {
		c_last = ds.randomCLast();
	} else {
		c_id = ds.randomNonUniformInt(1023, 1, 3000, 867);
	}

    return runOrderStatus(log, db, w_id, d_id, customer_based_on_last_name, c_id, c_last, context);
}

bool executeDelivery(std::ostream& log, DataSource& ds, DB& db, Identifier w_id, const ExecutionContext context) {
    // generate random carrier id and current timestamp
    Identifier carrier_id = ds.randomUniformInt(1, 10);
    DateTime ol_delivery_d(ds.getCurrentTimestamp());

    return runDelivery(log, db, w_id, carrier_id, ol_delivery_d, context);
}

bool executeStockLevel(std::ostream& log, DataSource& ds, DB& db, Identifier w_id, Identifier d_id, const ExecutionContext context) {
	// 2.8.1.2
	int32_t threshold = ds.randomUniformInt(10, 20);

    return runStockLevel(log, db, w_id, d_id, threshold, context);
}

enum class BenchmarkState {
    Warmup,
    Benchmark,
    Done
};

class LatencyLog {
public:
    // no logging
    LatencyLog() { }

    // log to file at 'path'
    LatencyLog(const std::string& path) : file(path), begin(std::chrono::steady_clock::now()) {
        if (!file)
            throw std::runtime_error("Failed to open latency log file for writing");
        // elapsed = [elapsed time since start]
        // measurement = [query or transaction name]
        // time = [runtime in microseconds]
        file << "elapsed,measurement,time" << std::endl;
    }

    void log(const std::string& measurement, size_t time_us) {
        if (!file)
            return;
        std::lock_guard<std::mutex> guard(fmutex);
        double elapsed = std::chrono::duration_cast<std::chrono::duration<double>>(std::chrono::steady_clock::now() - begin).count();
        file << elapsed << "," << measurement << "," << time_us << "\n";
    }

    operator bool() const {
        return file.is_open();
    }

private:
    std::ofstream file;
    std::mutex fmutex;
    std::chrono::steady_clock::time_point begin;
};

struct OLTPTotals {
    std::atomic_size_t success_count[5] = {};
    std::atomic_size_t fail_count[5] = {};
};

void OLTPStream(size_t id, std::chrono::steady_clock::time_point experiment_begin, std::atomic<BenchmarkState>& state, std::atomic_size_t& active_streams, std::ostream& log, LatencyLog& llog, DB& db, std::atomic_size_t& no_success_count, OLTPTotals& total_counts, uint32_t num_warehouses, Identifier w_id, Identifier d_id, const ExecutionContext context) {
    DataSource ds(num_warehouses, id);

    int32_t decision;
    uint32_t success_count[5] = {};
    uint32_t fail_count[5] = {};
    BenchmarkState prev_state = state.load();
    auto begin = std::chrono::steady_clock::now();
    while (state != BenchmarkState::Done) {
        auto time_since_experiment_begin = std::chrono::steady_clock::now() - experiment_begin;
        if (FLAGS_oltp_pause >= 0 && time_since_experiment_begin >= std::chrono::seconds(FLAGS_oltp_pause) && time_since_experiment_begin <= std::chrono::seconds(FLAGS_oltp_pause + 10)) {
            auto delta = std::chrono::seconds(FLAGS_oltp_pause + 10) - time_since_experiment_begin;
            if (delta > std::chrono::milliseconds(100))
                std::this_thread::sleep_for(delta / 2);
            continue;
        }
        BenchmarkState curr_state = state.load();
        if (curr_state == BenchmarkState::Benchmark && prev_state == BenchmarkState::Warmup) {
            begin = std::chrono::steady_clock::now();
        }
        prev_state = curr_state;
        decision = ds.randomUniformInt(1, 100);
        if (decision <= 44) {
            auto txn_begin = std::chrono::steady_clock::now();
            if (executeNewOrder(log, ds, db, w_id, context)) {
                no_success_count++;
                if (state == BenchmarkState::Benchmark)
                    success_count[0]++;
            } else {
                if (state == BenchmarkState::Benchmark)
                    fail_count[0]++;
            }
            llog.log("N", std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - txn_begin).count());
        }
        decision = ds.randomUniformInt(1, 100);
        if (decision <= 44) {
            auto txn_begin = std::chrono::steady_clock::now();
            if (executePayment(log, ds, db, w_id, context)) {
                if (state == BenchmarkState::Benchmark)
                    success_count[1]++;
            } else {
                if (state == BenchmarkState::Benchmark)
                    fail_count[1]++;
            }
            llog.log("P", std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - txn_begin).count());
        }
        decision = ds.randomUniformInt(1, 100);
        if (decision <= 4) {
            auto txn_begin = std::chrono::steady_clock::now();
            if (executeOrderStatus(log, ds, db, w_id, context)) {
                if (state == BenchmarkState::Benchmark)
                    success_count[2]++;
            } else {
                if (state == BenchmarkState::Benchmark)
                    fail_count[2]++;
            }
            llog.log("O", std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - txn_begin).count());
        }
        decision = ds.randomUniformInt(1, 100);
        if (decision <= 4) {
            auto txn_begin = std::chrono::steady_clock::now();
            if (executeDelivery(log, ds, db, w_id, context)) {
                if (state == BenchmarkState::Benchmark)
                    success_count[3]++;
            } else {
                if (state == BenchmarkState::Benchmark)
                    fail_count[3]++;
            }
            llog.log("D", std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - txn_begin).count());
        }
        decision = ds.randomUniformInt(1, 100);
        if (decision <= 4) {
            auto txn_begin = std::chrono::steady_clock::now();
            if (executeStockLevel(log, ds, db, w_id, d_id, context)) {
                if (state == BenchmarkState::Benchmark)
                    success_count[4]++;
            } else {
                if (state == BenchmarkState::Benchmark)
                    fail_count[4]++;
            }
            llog.log("S", std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - txn_begin).count());
        }
    }
    // 5.4.2
    //double mqth = success_count[0] / std::chrono::duration_cast<std::chrono::duration<double, std::ratio<60>>>(std::chrono::steady_clock::now() - begin).count();
    //std::cout << "Transaction throughput: " << size_t(mqth) << " tpmC" << std::endl;
    for (size_t i = 0; i < 5; ++i) {
        total_counts.success_count[i] += success_count[i];
        total_counts.fail_count[i] += fail_count[i];
    }
    active_streams--;
}

void OLAPStream(std::atomic<BenchmarkState>& state, std::atomic_size_t& active_streams, std::ostream& log, LatencyLog& llog, DB& db, const ExecutionContext context) {
    std::vector<double> response_times;
    BenchmarkState prev_state = state.load();
    auto begin = std::chrono::steady_clock::now();
    std::string current_query = FLAGS_olap == "mixed" ? "q06" : FLAGS_olap;
    while (state != BenchmarkState::Done) {
        auto q_begin = std::chrono::steady_clock::now();
        BenchmarkState curr_state = state.load();
        if (curr_state == BenchmarkState::Benchmark && prev_state == BenchmarkState::Warmup) {
            begin = std::chrono::steady_clock::now();
        }
        prev_state = curr_state;

        if (state == BenchmarkState::Warmup)
            continue;

        if (current_query == "q06") {
            /*
                select	sum(ol_amount) as revenue
                from	orderline
                where	ol_delivery_d >= '1999-01-01 00:00:00.000000'
                    and ol_delivery_d < '2020-01-01 00:00:00.000000'
                    and ol_quantity between 1 and 100000
            */
            std::vector<std::unique_ptr<ExecutablePipeline>> pipelines;
            pipelines.push_back(std::make_unique<ExecutablePipeline>(0));
            pipelines[0]->addOperator(std::make_shared<Q06ScanOperator>(db, context));
            BatchDescription output_desc = BatchDescription(std::vector<NamedColumn>({ NamedColumn(std::string("revenue"), std::make_shared<UnencodedTemporaryColumn<Decimal<2>>>()) }));
            pipelines[0]->addBreaker(std::make_shared<Q06AggregationOperator>(db, output_desc));
            auto qep = std::make_shared<QEP>(std::move(pipelines));
            qep->begin(context);
            qep->waitForExecution(context, db.vmcache, false);
            printQueryResult(qep->getResult(), context.getWorkerId(), FLAGS_olap_stdout ? std::cout : log);
            qep = nullptr;
        } else if (current_query == "q09") {
            log << "Running q09..." << std::endl;
            /*
                select	 n_name, extract(year from o_entry_d) as l_year, sum(ol_amount) as sum_profit
                from	 "ITEM", "STOCK", "SUPPLIER", "ORDERLINE", "ORDER", "NATION"
                where	 ol_i_id = s_i_id
                    and ol_supply_w_id = s_w_id
                    and mod((s_w_id * s_i_id), 10000) = su_suppkey
                    and ol_w_id = o_w_id
                    and ol_d_id = o_d_id
                    and ol_o_id = o_id
                    and ol_i_id = i_id
                    and su_nationkey = n_nationkey
                    and i_data like '%BB'
                group by n_name, extract(year from o_entry_d)
                order by n_name, l_year desc
            */

            std::vector<std::unique_ptr<ExecutablePipeline>> pipelines;
            // (0) scan NATION into JoinBreaker for SUPPLIER join
            pipelines.push_back(std::make_unique<ExecutablePipeline>(pipelines.size(), db, "NATION", std::vector<NamedColumn>({ N_NATIONKEY, N_NAME }), context));
            pipelines.back()->addJoinBreaker(db.vmcache, context);

            // (1) + (2) hash build for (0)
            JoinFactory::createBuildPipelines(pipelines, db.vmcache, *pipelines.back(), N_NATIONKEY.column->getValueTypeSize());

            // (3) scan SUPPLIER, join on (2), into JoinBreaker for STOCK join
            pipelines.push_back(std::make_unique<ExecutablePipeline>(pipelines.size(), db, "SUPPLIER", std::vector<NamedColumn>({ SU_NATIONKEY, SU_SUPPKEY }), context));
            pipelines.back()->addJoinProbe(db.vmcache, *pipelines[2], std::vector<NamedColumn>({ SU_SUPPKEY, N_NAME }));
            pipelines.back()->addJoinBreaker(db.vmcache, context);

            // (4) + (5) hash build for (3)
            JoinFactory::createBuildPipelines(pipelines, db.vmcache, *pipelines.back(), SU_SUPPKEY.column->getValueTypeSize());

            // (6) scan STOCK, compute '(S_W_ID * S_I_ID) % 10000' as the join key, join on (5), into JoinBreaker for ORDERLINE, ORDER, ITEM join
            // TODO: simplify this using ExecutablePipeline's specialised scan constructor once the general-purpose scan operator can do the necessary input transformations or we have a seperate operator for performing arithmetic operations
            pipelines.push_back(std::make_unique<ExecutablePipeline>(pipelines.size()));
            auto p6_output_columns = std::vector<NamedColumn>({ S_SUPPKEY, S_W_ID, S_I_ID });
            for (const auto& col : p6_output_columns) {
                pipelines.back()->current_columns.addColumn(col.name, col.column);
            }
            pipelines.back()->addOperator(std::make_shared<Q09StockScanOperator>(db, context));
            pipelines.back()->addJoinProbe(db.vmcache, *pipelines[5], std::vector<NamedColumn>({
                S_W_ID,
                S_I_ID,
                N_NAME
            }));
            pipelines.back()->addJoinBreaker(db.vmcache, context);

            // (7) + (8) hash build for (6)
            JoinFactory::createBuildPipelines(pipelines, db.vmcache, *pipelines.back(), S_W_ID.column->getValueTypeSize() + S_I_ID.column->getValueTypeSize());

            // (9) scan ITEM into JoinBreaker for ORDERLINE join
            pipelines.push_back(std::make_unique<ExecutablePipeline>(pipelines.size()));
            auto p9_output_columns = std::vector<NamedColumn>({ I_ID });
            for (const auto& col : p9_output_columns) {
                pipelines.back()->current_columns.addColumn(col.name, col.column);
            }
            pipelines.back()->addOperator(std::make_shared<Q09ItemScanOperator>(db, context));
            pipelines.back()->addJoinBreaker(db.vmcache, context);

            // (10) + (11) hash build for (9)
            JoinFactory::createBuildPipelines(pipelines, db.vmcache, *pipelines.back(), I_ID.column->getValueTypeSize());

            // (12) scan ORDERLINE, join on ITEM, into JoinBreaker for ORDER join
            pipelines.push_back(std::make_unique<ExecutablePipeline>(pipelines.size(), db, "ORDERLINE", std::vector<NamedColumn>({ OL_I_ID, OL_W_ID, OL_D_ID, OL_O_ID, OL_SUPPLY_W_ID, OL_AMOUNT }), context));
            pipelines.back()->addJoinProbe(db.vmcache, *pipelines[11], std::vector<NamedColumn>({ OL_W_ID, OL_D_ID, OL_O_ID, OL_I_ID, OL_SUPPLY_W_ID, OL_AMOUNT }));
            pipelines.back()->addJoinBreaker(db.vmcache, context);

            // (13) + (14) hash build for (12)
            JoinFactory::createBuildPipelines(pipelines, db.vmcache, *pipelines.back(), OL_W_ID.column->getValueTypeSize() + OL_D_ID.column->getValueTypeSize() + OL_O_ID.column->getValueTypeSize());

            // (15) scan ORDER, join on (14) and (8), into sort breaker
            pipelines.push_back(std::make_unique<ExecutablePipeline>(pipelines.size()));
            auto p15_output_columns = std::vector<NamedColumn>({ O_W_ID, O_D_ID, O_ID, L_YEAR });
            for (const auto& col : p15_output_columns) {
                pipelines.back()->current_columns.addColumn(col.name, col.column);
            }
            pipelines.back()->addOperator(std::make_shared<Q09OrderScanOperator>(db, context));
            pipelines.back()->addJoinProbe(db.vmcache, *pipelines[14], std::vector<NamedColumn>({ OL_SUPPLY_W_ID, OL_I_ID, OL_AMOUNT, L_YEAR }));
            pipelines.back()->addJoinProbe(db.vmcache, *pipelines[8], std::vector<NamedColumn>({ N_NAME, L_YEAR, OL_AMOUNT }));
            pipelines.back()->addSortBreaker(std::vector<NamedColumn>({ N_NAME, L_YEAR }), std::vector<Order>({ Order::Ascending, Order::Descending }), context.getWorkerCount());

            // (16) sort (15), aggregate SUM(OL_AMOUNT) grouped by N_NAME, L_YEAR
            pipelines.push_back(std::make_unique<ExecutablePipeline>(pipelines.size()));
            pipelines.back()->addSort(db.vmcache, *pipelines[pipelines.size() - 2]);
            BatchDescription final_output_desc = BatchDescription(std::vector<NamedColumn>({ N_NAME, L_YEAR, SUM_PROFIT }));
            pipelines.back()->addBreaker(std::make_shared<Q09AggregationOperator>(db, final_output_desc));

            auto qep = std::make_shared<QEP>(std::move(pipelines));
            qep->begin(context);
            qep->waitForExecution(context, db.vmcache, false);
            printQueryResult(qep->getResult(), context.getWorkerId(), FLAGS_olap_stdout ? std::cout : log);
            qep = nullptr;
        } else if (current_query == "simulated") {
            log << "Simulating OLAP query..." << std::endl;
            const size_t num_pages = std::min(db.vmcache.getMaxPhysicalPages() * 50ull / 100ull, 4ull * 1024ull * 1024ull * 1024ull / PAGE_SIZE);
            const size_t batch_size = num_pages;
            size_t allocated_pages = 0;
            std::vector<char*> pages;
            // "analytical query": allocate a large number of temporary pages in vmcache
            while (state != BenchmarkState::Done && allocated_pages < num_pages) {
                pages.push_back(db.vmcache.allocateTemporaryHugePage(batch_size, context.getWorkerId()));
                allocated_pages += batch_size;
            }
            // hold allocated pages
            while (std::chrono::steady_clock::now() - q_begin < std::chrono::seconds(FLAGS_olap_sim_duration)) {
                std::this_thread::sleep_for(std::chrono::microseconds(500));
            }
            auto dealloc_begin = std::chrono::steady_clock::now();
            // drop allocated pages
            for (auto& page : pages) {
                db.vmcache.dropTemporaryHugePage(page, batch_size, context.getWorkerId());
            }
            llog.log("free", std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - dealloc_begin).count());
        }
        auto q_elapsed = std::chrono::steady_clock::now() - q_begin;
        response_times.push_back(std::chrono::duration_cast<std::chrono::duration<double>>(q_elapsed).count());
        llog.log(current_query == "simulated" ? "sim_olap" : current_query, std::chrono::duration_cast<std::chrono::microseconds>(q_elapsed).count());
        if (FLAGS_olap == "mixed") { // alternate between q06 and q09 in mixed mode
            if (current_query == "q06") {
                current_query = "q09";
            } else {
                current_query = "q06";
            }
        }
        // wait between each query execution
        while (state != BenchmarkState::Done && std::chrono::steady_clock::now() - q_begin < std::chrono::seconds(FLAGS_olap_interval)) {
            std::this_thread::sleep_for(std::chrono::microseconds(500));
        }
    }
    if (!response_times.empty()) {
        std::sort(response_times.begin(), response_times.end());
        std::cout << "Analytical mean response time: " << std::setprecision(3) << response_times[response_times.size() / 2] << " s" << std::endl;
        std::cout << "Analytical throughput: " << std::setprecision(3) << response_times.size() / std::chrono::duration_cast<std::chrono::duration<double>>(std::chrono::steady_clock::now() - begin).count() << " queries/s" << std::endl;
    } else {
        std::cout << "No analytical queries completed within the benchmark period!" << std::endl;
    }
    active_streams--;
}

} // namespace tpcch


int main(int argc, char** argv) {
#ifdef VTUNE_PROFILING
    __itt_task_begin(itt_domain, __itt_null, __itt_null, itt_handle_setup);
#endif

    gflags::ParseCommandLineFlags(&argc, &argv, true);
    if (argc != 2) {
        std::cout << "Error: Missing database path" << std::endl;
        return -1;
    }

    const char* const supported_partitioning_strategies[] = { "basic", "partitioned" };
    bool partitioning_strategy_valid = false;
    for (size_t i = 0; i < sizeof(supported_partitioning_strategies) / sizeof(supported_partitioning_strategies[0]); i++) {
        if (FLAGS_partitioning_strategy == supported_partitioning_strategies[i]) {
            partitioning_strategy_valid = true;
            break;
        }
    }
    if (!partitioning_strategy_valid) {
        std::cout << "Error: " << FLAGS_partitioning_strategy << " is not a supported partitioning strategy" << std::endl;
        return -1;
    }

    const char* const supported_eviction_policies[] = { "clock", "random", "mru" };
    bool eviction_policy_valid = false;
    for (size_t i = 0; i < sizeof(supported_eviction_policies) / sizeof(supported_eviction_policies[0]); i++) {
        if (FLAGS_eviction_policy == supported_eviction_policies[i]) {
            eviction_policy_valid = true;
            break;
        }
    }
    if (!eviction_policy_valid) {
        std::cout << "Error: " << FLAGS_eviction_policy << " is not a supported eviction policy" << std::endl;
        return -1;
    }

    const char* const supported_olap_workloads[] = { "simulated", "q06", "q09", "mixed", "none" };
    bool olap_valid = false;
    for (size_t i = 0; i < sizeof(supported_olap_workloads) / sizeof(supported_olap_workloads[0]); i++) {
        if (FLAGS_olap == supported_olap_workloads[i]) {
            olap_valid = true;
            break;
        }
    }
    if (!olap_valid) {
        std::cout << "Error: " << FLAGS_olap << " is not a supported OLAP workload" << std::endl;
        return -1;
    }

    // path to the database file
    std::string path(argv[1]);

    // set up eviction policy
    std::unique_ptr<PartitioningStrategy> partitioning_strategy;
    if (FLAGS_partitioning_strategy == "basic") {
        partitioning_strategy = createPartitioningStrategy<BasicPartitioningStrategy>(FLAGS_eviction_policy);
    } else if (FLAGS_partitioning_strategy == "partitioned") {
        if (FLAGS_partitioned_num_temp_pages == 0) {
            std::cout << "Error: Please specify a non-zero value for 'partitioned_num_temp_pages' for the partitioned strategy!" << std::endl;
            return -1;
        }
        partitioning_strategy = createPartitioningStrategy<DataTempPartitioningStrategy>(FLAGS_eviction_policy, FLAGS_partitioned_num_temp_pages);
    }

    int ret = 0;
    {
        uint64_t num_threads = JobManager::configureNumThreads(FLAGS_parallel);
        DB db(FLAGS_memory_limit, path, FLAGS_sandbox, FLAGS_no_dirty_writeback, !FLAGS_no_async_flush, !FLAGS_no_eviction_target, num_threads, FLAGS_exmap, true, std::move(partitioning_strategy), 16ull * 1024ull * 1024ull); // 16M pages = 64 GiB max DB size
        JobManager job_manager(num_threads, db);
        ExecutionContext context(job_manager, db, 0, 0);

#ifdef VTUNE_PROFILING
        __itt_task_end(itt_domain);
#endif
        if (db.getNumTables(context.getWorkerId()) == 0) {
#ifdef VTUNE_PROFILING
            __itt_task_begin(itt_domain, __itt_null, __itt_null, itt_handle_load);
#endif
            // load data
            if (FLAGS_ch_path.length() == 0) {
                std::cout << "Error: Missing value for argument ch_path" << std::endl;
                ret = -1;
            } else if (!tpcch::loadDatabase(db, context)) {
                ret = -1;
            }
#ifdef VTUNE_PROFILING
            __itt_task_end(itt_domain);
#endif
        }

        bool stop_stats_collection = false;
        std::unique_ptr<std::thread> stats_collector_thread;
        std::atomic_size_t no_success_count(0);
        tpcch::OLTPTotals oltp_counts;
        if (!FLAGS_collect_stats.empty()) {
            size_t collection_interval_ms = FLAGS_benchmark >= 1000 ? 1000 : (FLAGS_benchmark >= 500 ? 100 : (FLAGS_benchmark >= 100 ? 10 : 1));
            std::cout << "Collecting statistics in " << collection_interval_ms << " ms intervals" << std::endl;
            // begin statistics collection
            stats_collector_thread = std::make_unique<std::thread>(tpcch::statsCollectorThread, std::ref(FLAGS_collect_stats), std::ref(stop_stats_collection), std::ref(db), std::ref(no_success_count), collection_interval_ms);
        }

        // run benchmark
        if (!FLAGS_import_only) {
            if (FLAGS_oltp != 0 && FLAGS_olap != "none" && FLAGS_oltp + 2 > job_manager.getWorkerCount()) {
                ret = -1;
                std::cerr << "Number of OLTP streams (" << FLAGS_oltp << ") must be at least 2 fewer than the number of worker threads (" << job_manager.getWorkerCount() << ") when running concurrent OLAP queries" << std::endl;
            } else if (tpcch::validateDatabase(db, FLAGS_full_validation)) {
                std::atomic<tpcch::BenchmarkState> state(tpcch::BenchmarkState::Warmup);
                std::atomic_size_t active_streams(0);

                PageId warehouse_basepage_id = db.getTableBasepageId("WAREHOUSE", context.getWorkerId());
                PageId warehouse_visibility_basepage = SharedGuard<TableBasepage>(db.vmcache, warehouse_basepage_id, context.getWorkerId())->visibility_basepage;
                const uint32_t num_warehouses = BTree<RowId, bool>(db.vmcache, warehouse_visibility_basepage, context.getWorkerId()).getCardinality();
                std::cout << "Running benchmarks with " << num_warehouses << " warehouses and " << FLAGS_oltp << " OLTP streams" << std::endl;
                tpcch::DataSource ds(num_warehouses);
                std::ofstream log; // for now just suppress log output from streams, may change this later on
                //auto& log = std::cout;
                tpcch::LatencyLog llog = FLAGS_latency_log.empty() ? tpcch::LatencyLog() : tpcch::LatencyLog(FLAGS_latency_log);
                if (llog)
                    db.vmcache.setAllocationLatencyLogCallback(std::make_shared<std::function<void(size_t)>>(std::bind(&tpcch::LatencyLog::log, &llog, "alloc", std::placeholders::_1)));
                std::vector<std::shared_ptr<FunctionTask>> oltp_tasks;
                std::set<uint64_t> used_w_d_id_combinations;
                const auto begin = std::chrono::steady_clock::now();
                for (size_t i = 0; i < FLAGS_oltp; i++) {
                    Identifier w_id;
                    Identifier d_id;
                    uint64_t combination;
                    do {
                        // 2.4.1.1
                        w_id = ds.randomUniformInt(1, num_warehouses);
                        // 2.8.1.1
                        d_id = ds.randomUniformInt(1, 10);
                        // for checking if we already used this combination
                        combination = static_cast<uint64_t>(w_id) << 32 | d_id;
                    } while (used_w_d_id_combinations.find(combination) != used_w_d_id_combinations.end());
                    used_w_d_id_combinations.emplace(combination);
                    oltp_tasks.push_back(std::make_shared<FunctionTask>(std::bind(tpcch::OLTPStream, i, begin, std::ref(state), std::ref(active_streams), std::ref(log), std::ref(llog), std::ref(db), std::ref(no_success_count), std::ref(oltp_counts), num_warehouses, w_id, d_id, std::placeholders::_1)));
                }

                for (auto& task : oltp_tasks) {
                    job_manager.getDispatcher().scheduleJob(task, context); active_streams++;
                }
                if (FLAGS_olap != "none") {
                    auto olap_task = std::make_shared<FunctionTask>(std::bind(tpcch::OLAPStream, std::ref(state), std::ref(active_streams), std::ref(log), std::ref(llog), std::ref(db), std::placeholders::_1));
                    job_manager.getDispatcher().scheduleJob(olap_task, context); active_streams++;
                }

                const auto warmup_time = std::chrono::seconds(FLAGS_warmup);
                const auto benchmark_time = std::chrono::seconds(FLAGS_benchmark);
                for (size_t i = 0; i < 2; i++) {
                    if (i == 0) {
                        std::cout << "Beginning warmup (" << FLAGS_warmup << " s) ..." << std::endl;
                    } else {
                        std::cout << "Beginning benchmark (" << FLAGS_benchmark << " s) ..." << std::endl;
                    }
                    const auto run_time = i == 0 ? warmup_time : warmup_time + benchmark_time;
                    while (std::chrono::steady_clock::now() - begin < run_time) {
                        std::this_thread::sleep_for(std::chrono::milliseconds(1));
                    }
                    if (i == 0) {
                        state.store(tpcch::BenchmarkState::Benchmark);
                    } else {
                        std::cout << "Ending benchmark..." << std::endl;
                        state.store(tpcch::BenchmarkState::Done);
                    }
                }
                // wait for last queries/txns to finish before shutting down worker threads
                while (active_streams > 0) {
                    std::this_thread::sleep_for(std::chrono::milliseconds(1));
                }
                // report OLTP throughput
                double mqth = oltp_counts.success_count[0] / std::chrono::duration_cast<std::chrono::duration<double, std::ratio<60>>>(benchmark_time).count();
                size_t total_count = 0;
                for (size_t i = 0; i < 5; ++i)
                    total_count += oltp_counts.success_count[i] + oltp_counts.fail_count[i];
                std::cout << "Transactional throughput: " << size_t(mqth) << " tpmC" << std::endl;
                // report totals
                const char* txn_names[] = {
                    "NewOrder",
                    "Payment",
                    "OrderStatus",
                    "Delivery",
                    "StockLevel"
                };
                std::cout << "Total number of transactions executed after warmup (success/fail):" << std::endl;
                for (size_t i = 0; i < 5; ++i) {
                    std::cout << "\t" << txn_names[i] << ": ";
                    std::cout << oltp_counts.success_count[i] << "/" << oltp_counts.fail_count[i];
                    double oltp_mix_percentage = static_cast<double>(oltp_counts.success_count[i] + oltp_counts.fail_count[i]) / total_count * 100;
                    std::cout << " (" << std::fixed << std::setprecision(1) << oltp_mix_percentage << "%)";
                    std::cout << std::endl;
                }
            }
        }

        if (!FLAGS_collect_stats.empty()) {
            // stop statistics collection
            stop_stats_collection = true;
            stats_collector_thread->join();
        }

        job_manager.stop();
    }

    return ret;
}